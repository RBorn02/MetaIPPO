Started worker 0
Started worker 1
Started worker 2
Started worker 3
Started worker 4
Started worker 5
Started worker 6
Started worker 7
Initializing workers...
Parameter containing:
tensor([[0., 0., 0., 0.]], requires_grad=True)
Predicted values mean: 0.00011445191921666265; Returns mean: -1.0390612814603628e-09; Advantages mean: -0.015845157206058502; Values mean: 0.015845157206058502
Actions mean: 0.0038779363967478275; Actions std: 1.0008107423782349
Action logprob mean: -5.678946018218994; Action logprob std: 1.4275238513946533
Agent_0 loss total: -0.0052627357363235205; pg loss: -0.0003472325661346143; value loss: 0.0007612571835124982; entropy loss: 5.676760017871857; explained variance: -56252432383999.0; clip fracs: 0.0
Parameter containing:
tensor([[0., 0., 0., 0.]], requires_grad=True)
Predicted values mean: 0.007566924672573805; Returns mean: 2.159867978912544e-10; Advantages mean: -0.11232433468103409; Values mean: 0.11232433468103409
Actions mean: 0.0057398248463869095; Actions std: 0.9961228370666504
Action logprob mean: -5.660225868225098; Action logprob std: 1.3862426280975342
Agent_1 loss total: -0.003501092840451747; pg loss: -0.0002468661406146433; value loss: 0.002419189564534463; entropy loss: 5.673415988683701; explained variance: -184061293232127.0; clip fracs: 0.0
Time to update policy: 4.74056601524353
Epoch: 1
Agent_0: Completed 128.0 Episodes;
Total Reward: 0.0; Average Reward This Epoch: 0.0; Rolling Average Reward: 0.0 Best Average Reward: 0.0
Successes: 0.0; Success Rate: 0.0; Rolling Average Sucess Rate: 0.0; Best Rolling Average Sucess Rate: 0.0
Stage 1: 0.0 Successes; 128.0 Samples; 0.0 Success Rate; 0.0 Rolling Average Success Rate
Stage 2: 0.0 Successes; 128.0 Samples; 0.0 Success Rate; 0.0 Rolling Average Success Rate
Stage 3: 0.0 Successes; 128.0 Samples; 0.0 Success Rate; 0.0 Rolling Average Success Rate
Agent_1: Completed 128.0 Episodes;
Total Reward: 0.0; Average Reward This Epoch: 0.0; Rolling Average Reward: 0.0 Best Average Reward: 0.0
Successes: 0.0; Success Rate: 0.0; Rolling Average Sucess Rate: 0.0; Best Rolling Average Sucess Rate: 0.0
Stage 1: 0.0 Successes; 128.0 Samples; 0.0 Success Rate; 0.0 Rolling Average Success Rate
Stage 2: 0.0 Successes; 128.0 Samples; 0.0 Success Rate; 0.0 Rolling Average Success Rate
Stage 3: 0.0 Successes; 128.0 Samples; 0.0 Success Rate; 0.0 Rolling Average Success Rate
Traceback (most recent call last):
  File "/home/rbornema/Documents/GitHub/MetaIPPO/mp_train.py", line 424, in <module>
    if all(np.array(done, dtype=bool)):
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/rbornema/Documents/GitHub/MetaIPPO/mp_train.py", line 424, in <module>
    if all(np.array(done, dtype=bool)):
KeyboardInterrupt